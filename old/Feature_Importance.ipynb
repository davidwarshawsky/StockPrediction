{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bayes_opt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-46ad93033d56>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;31m#hyperparameter tuning\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mbayes_opt\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mBayesianOptimization\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mshap\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'bayes_opt'"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "#Data Import and Timing\n",
    "import pandas_datareader.data as dr\n",
    "import datetime \n",
    "\n",
    "#Graphing\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#Setting up model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler,RobustScaler\n",
    "\n",
    "#hyperparameter tuning \n",
    "from bayes_opt import BayesianOptimization\n",
    "import shap\n",
    "\n",
    "#Learners\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import Lasso,Ridge,RidgeCV,LinearRegression\n",
    "import lightgbm as lgb\n",
    "\n",
    "#feature calculation\n",
    "import ta\n",
    "\n",
    "import featuretools as ft\n",
    "\n",
    "from tsfresh import extract_relevant_features\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "from Stock_Utility_functions import *\n",
    "\n",
    "def BestStackFinder(**weights):\n",
    "    #\"best compilation determiner\"\n",
    "    global for_weight_preds\n",
    "    import pandas as pd\n",
    "    preds=for_weight_preds\n",
    "    weight_list = []\n",
    "\n",
    "    ## returns vars to use for multiplication\n",
    "\n",
    "    for key, value in weights.items():\n",
    "        weight_list.append(value)\n",
    "\n",
    "    ## Multiply stacking weights by predictions and add them up\n",
    "    comb_preds = np.zeros(preds.shape[0])\n",
    "    Y_test = preds.iloc[:,0]\n",
    "    preds = preds.iloc[:,1:]\n",
    "    for weight,col in zip( weight_list, preds.columns.values):\n",
    "        comb_preds1 = weight*np.asarray(preds[col])\n",
    "        comb_preds = comb_preds +comb_preds1 \n",
    "\n",
    "    Y_Test_Categorical = np.where(Y_test.values <= 0, 0, 1)\n",
    "    Preds_Categorical = np.where(comb_preds <= 0, 0, 1)\n",
    "    return -1*(mean_absolute_error(Y_test,comb_preds))\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records=process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df = pd.DataFrame(records,columns=['Tickers',\"Company_Name\",\"Industry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gplearn.functions import make_function\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "\n",
    "def th(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "gptanh = make_function(th, 'tanh', 1)\n",
    "function_set = ['add', 'sub', 'mul', 'div', 'inv', 'abs', 'neg', 'max', 'min', gptanh]\n",
    "\n",
    "model = SymbolicRegressor(metric = 'mean absolute error',stopping_criteria=20,n_jobs = -1)\n",
    "\n",
    "# estimator.fit(XX_train,YY_train)\n",
    "# print(estimator.score(XX_test, YY_test,deep=True))\n",
    "\n",
    "# estimator.fit(X_train,Y_train)\n",
    "# genetic_preds = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Webscraping\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from os import mkdir\n",
    "from os.path import exists, join\n",
    "import urllib.request as request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_PARAMS = {'num_leaves': 200,\n",
    "            'boosting_type': 'dart',\n",
    "             'min_data_in_leaf': 30, \n",
    "             'learning_rate': 0.02,\n",
    "             \"min_child_samples\": 2,\n",
    "             \"feature_fraction\": 0.9,\n",
    "             \"bagging_freq\": 5,\n",
    "             \"bagging_fraction\": 0.9 ,\n",
    "             \"bagging_seed\": 11,\n",
    "             \"metric\": 'mae',\n",
    "             \"lambda_l1\": 0.1,\n",
    "             \"verbosity\": -1,\n",
    "             \"nthread\": 4,\n",
    "             \"random_state\": 4590}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start_date = '2017-10-02'\n",
    "train_stop_date  = '2019-10-17'\n",
    "shift_window_of_days = 1\n",
    "\n",
    "\n",
    "Tommorow_Predictions = []\n",
    "ticker_for_number_features = 'EBAY'\n",
    "Official_Train_Set,target = gen_feats(ticker_for_number_features,train_start_date,train_stop_date,shift_window_of_days)\n",
    "number_of_features = len(Official_Train_Set.columns)\n",
    "\n",
    "for Industry in list(ticker_df['Industry'].unique())[6:8]:\n",
    "    print('----------------------------'+Industry+'------------------------------')\n",
    "    tickers = list(ticker_df.loc[ticker_df['Industry'] == Industry,'Tickers'])\n",
    "    \n",
    "    run_over = tickers[:6]\n",
    "    # Repeat the process happening in the loop below, but with every one of the previous stocks\n",
    "    for ticker in run_over:\n",
    "        \n",
    "        for_weight_preds = pd.DataFrame()\n",
    "        \n",
    "        final_preds = pd.DataFrame()\n",
    "        preds = pd.DataFrame()\n",
    "        \n",
    "        Master_DataFrame = pd.DataFrame()\n",
    "        Targets_DataFrame = pd.DataFrame()\n",
    "        \n",
    "        tickers_for_loop = run_over\n",
    "        \n",
    "        Official_Train_Set,target = gen_feats(ticker,train_start_date,train_stop_date,shift_window_of_days)\n",
    "        Official_Train_Set_1, Official_Train_Set_2, target_1, target_2 = train_test_split(Official_Train_Set,target,\n",
    "                                                                test_size =0.5,shuffle = False)\n",
    "\n",
    "        tickers_for_loop.remove(ticker)\n",
    "        for_weight_preds['target'] = target_1.values.flatten()\n",
    "        #Every other stock is trained on, and then, the booster predicts on the holdout stock. results are weighted.\n",
    "        for iteration_number,ticker1 in enumerate(tickers_for_loop):\n",
    "            \n",
    "            X_T,Y_T = gen_feats(ticker1,train_start_date,train_stop_date,shift_window_of_days)\n",
    "            \n",
    "            Master_DataFrame = pd.concat((Master_DataFrame,X_T),axis=1)\n",
    "            Targets_DataFrame = pd.concat((Targets_DataFrame,Y_T),axis=1)\n",
    "            \n",
    "            X_train = Master_DataFrame.loc[:,[x for x in list(Master_DataFrame.columns) if ticker1 in x]]\n",
    "            Y_train = Targets_DataFrame[ticker1]\n",
    "#             model.fit(X_train, Y_train)\n",
    "            Train = lgb.Dataset(X_train, label=Y_train)\n",
    "\n",
    "            model = lgb.train(LGB_PARAMS,Train,num_boost_round =10)\n",
    "            \n",
    "            for_weight_preds['prediction'+str(iteration_number)] = model.predict(Official_Train_Set_1)\n",
    "            final_preds['prediction'+str(iteration_number)] = model.predict(Official_Train_Set_2)\n",
    "            \n",
    "        weights = ReturnBestStackingWeights(for_weight_preds,n_iter=2)\n",
    "        stacked_predictions = gen_stack_preds(final_preds,weights)    \n",
    "        \n",
    "        print('The Error  for '+ticker+' is '+str(mean_absolute_error(target_2,stacked_predictions)))\n",
    "\n",
    "    #      Find how accurate categorically\n",
    "        Y_Test_Categorical = np.where(target_2.values <= 0, 0, 1)\n",
    "        Preds_Categorical = np.where(stacked_predictions <= 0, 0, 1)\n",
    "        \n",
    "        print('Categorical Accuracy for '+ticker+ ' is '+str(accuracy_score(Y_Test_Categorical,Preds_Categorical)))\n",
    "#         Tommorow_Predictions.append([ticker,list(stacked_predictions)[-1]])\n",
    "#         if accuracy_score(Y_Test_Categorical,Preds_Categorical) >= 0.7:\n",
    "#             plt.figure(figsize=(30,30))\n",
    "#             plt.plot((np.abs(target_2.values[-100:])*np.where(target_2.values[-100:] == 0, -1, 1)))\n",
    "#             plt.plot(np.abs(stacked_predictions[-100:])*np.where(stacked_predictions[-100:] == 0, -1, 1))\n",
    "#             plt.show()\n",
    "#     print('-------------------------------------------------done!-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find drops and jumps \n",
    "# The criteria is on average change (std)\n",
    "# check to see if stock usually grows or drops, then check the current state in last 2-3 months (3 is used in case of more fluctiations, \n",
    "# eg. more drops or growth, this will help with bigger picture )\n",
    "# in cases of growth "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}