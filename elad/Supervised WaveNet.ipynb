{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport sys\nimport tensorflow as tf\nfrom keras.layers import Input, Dense, Lambda, Flatten, Reshape, Activation, Dropout, Add, TimeDistributed, Multiply, Conv1D, Conv2D, MaxPooling1D, AveragePooling1D\nfrom keras.models import Model, Sequential, load_model\nfrom keras import backend as K\nfrom keras import metrics\nfrom keras import optimizers\nfrom keras.callbacks import History, ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(tf.test.gpu_device_name())\n# # See https://www.tensorflow.org/tutorials/using_gpu#allowing_gpu_memory_growth\n# config = tf.compat.v1.ConfigProto()\n# config.gpu_options.allow_growth = True\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class WaveNetClassifier():\n    def __init__(self, input_shape, output_shape, kernel_size = 2, dilation_depth = 2, n_filters = 2, task = 'classification', regression_range = None, load=False, load_dir='./'):\n        \"\"\"\n        Parameters:\n          input_shape: (tuple) tuple of input shape. (e.g. If input is 6s raw waveform with sampling rate = 16kHz, (96000,) is the input_shape)\n          output_shape: (tuple)tuple of output shape. (e.g. If we want classify the signal into 100 classes, (100,) is the output_shape)\n          kernel_size: (integer) kernel size of convolution operations in residual blocks\n          dilation_depth: (integer) type total depth of residual blocks\n          n_filters: (integer) # of filters of convolution operations in residual blocks\n          task: (string) 'classification' or 'regression'\n          regression_range: (list or tuple) target range of regression task\n          load: (bool) load previous WaveNetClassifier or not\n          load_dir: (string) the directory where the previous model exists\n        \"\"\"     \n        self.task = task\n        # save task info\n        if task == 'regression':\n            if regression_range[0] == 0:\n                self.activation = 'sigmoid'\n                self.scale_ratio = regression_range[1]\n            elif regression_range[0] == - regression_range[1]:\n                self.activation = 'tanh'\n                self.scale_ratio = regression_range[1]\n            elif regression_range == None:\n                self.activation = 'linear'\n                self.scale_ratio = 1\n            else:\n                print('ERROR: wrong regression range')\n                sys.exit()  \n        elif task == 'classification':\n            self.activation = 'softmax'\n            self.scale_ratio = 1      \n        else:\n            print('ERROR: wrong task')\n            sys.exit()\n\n        # save input info\n        if len(input_shape) == 1:\n            self.expand_dims = True\n        elif len(input_shape) == 2:\n            self.expand_dims = False\n        else:\n            print('ERROR: wrong input shape')\n            sys.exit()\n        self.input_shape = input_shape\n\n        # save output info\n        if len(output_shape) == 1:\n            self.time_distributed = False\n        elif len(output_shape) == 2:\n            self.time_distributed = True\n        else:\n            print('ERROR: wrong output shape')\n            sys.exit()\n        self.output_shape = output_shape\n\n        # save hyperparameters of WaveNet\n        self.kernel_size = kernel_size\n        self.dilation_depth = dilation_depth\n        self.n_filters = n_filters\n        self.manual_loss = None\n\n\n        if load is True:\n            self.model = load_model(load_dir+\"saved_wavenet_clasifier.h5\", custom_objects={'tf':tf})\n            self.prev_history = pd.read_csv(load_dir+'wavenet_classifier_training_history.csv')\n            self.start_idx = len(self.prev_history)\n            self.history = None\n        else:\n            self.model = self.construct_model()\n            self.start_idx = 0\n            self.history = None\n            self.prev_history = None\n\n    \n    def residual_block(self, x, i):\n        tanh_out = Conv1D(self.n_filters, \n                          self.kernel_size, \n                          dilation_rate = self.kernel_size**i, \n                          padding='causal', \n                          name='dilated_conv_%d_tanh' % (self.kernel_size ** i), \n                          activation='tanh'\n                          )(x)\n        sigm_out = Conv1D(self.n_filters, \n                          self.kernel_size, \n                          dilation_rate = self.kernel_size**i, \n                          padding='causal', \n                          name='dilated_conv_%d_sigm' % (self.kernel_size ** i), \n                          activation='sigmoid'\n                          )(x)\n        z = Multiply(name='gated_activation_%d' % (i))([tanh_out, sigm_out])\n        skip = Conv1D(self.n_filters, 1, name='skip_%d'%(i))(z)\n        res = Add(name='residual_block_%d' % (i))([skip, x])\n        return res, skip\n  \n    def construct_model(self):    \n        x = Input(shape=self.input_shape, name='original_input')\n        if self.expand_dims == True:\n            x_reshaped = Reshape(self.input_shape + (1,), name='reshaped_input')(x)\n        else:\n            x_reshaped = x\n        skip_connections = []\n        out = Conv1D(self.n_filters, 2, dilation_rate=1, padding='causal', name='dilated_conv_1')(x_reshaped)\n        for i in range(1, self.dilation_depth + 1):\n            out, skip = self.residual_block(out,i)\n            skip_connections.append(skip)\n        out = Add(name='skip_connections')(skip_connections)\n        out = Activation('relu')(out)\n        out = Conv1D(self.n_filters, 80, strides = 1, padding='same', name='conv_5ms', activation = 'relu')(out)\n        out = AveragePooling1D(80, padding='same', name='downsample_to_200Hz')(out)\n        if self.time_distributed:\n            target_kernel_size = (int) (self.input_shape[0] / (80*self.output_shape[0])) # prev_len / x = target_len => x = prev_len / target_len\n            out = Conv1D(self.n_filters, target_kernel_size, padding='same', name = 'conv_fit_to_target', activation='relu')(out)\n            out = Conv1D(self.output_shape[1], target_kernel_size, padding='same', name='conv_final')(out)\n            out = AveragePooling1D(target_kernel_size, padding='same')(out)\n            out = TimeDistributed(Activation(self.activation))(out)\n        else:\n            out = Conv1D(self.n_filters, 100, padding='same', activation='relu', name='conv_500ms')(out)\n            out = Conv1D(self.output_shape[0], 100, padding='same', activation='relu', name='conv_500ms_target_shape')(out)\n            out = AveragePooling1D(100, padding='same',name = 'downsample_to_2Hz')(out)\n            out = Conv1D(self.output_shape[0], (int) (self.input_shape[0] / 8000), padding='same', name='final_conv')(out)\n            out = AveragePooling1D((int) (self.input_shape[0] / 8000), name='final_pooling')(out)\n            out = Reshape(self.output_shape)(out)\n            out = Activation(self.activation)(out)\n        if self.scale_ratio != 1:\n            out = Lambda(lambda x: x * self.scale_ratio, name='output_reshaped')(out)\n        model = Model(x, out)  \n        model.summary()\n        return model\n    \n    def get_model(self):\n        return self.model\n    \n    def add_loss(self, loss):\n        self.manual_loss = loss\n  \n    def fit(self, X, Y, validation_data = None, epochs = 100, batch_size = 32, optimizer='adam', save=False, save_dir='./'):\n        # set default losses if not defined\n        if self.manual_loss is not None:\n            loss = self.manual_loss\n            metrics = None\n        else:\n            if self.task == 'classification':\n                loss = 'categorical_crossentropy'\n                metrics = ['accuracy']\n            else:\n                loss = 'mean_squared_error'\n                metrics = None\n\n        # set callback functions\n        if save:\n            saved = save_dir + \"saved_wavenet_clasifier.h5\"\n            hist = save_dir + 'wavenet_classifier_training_history.csv'\n            if validation_data is None:\n                checkpointer = ModelCheckpoint(filepath=saved, monitor='loss', verbose=1, save_best_only=True)\n            else:\n                checkpointer = ModelCheckpoint(filepath=saved, monitor='val_loss', verbose=1, save_best_only=True)\n            history = History()\n            callbacks = [history, checkpointer]\n        else:\n            callbacks = None\n\n        # compile the model\n        self.model.compile(optimizer, loss, metrics)\n        try:\n            self.history = self.model.fit(X, Y, shuffle = True, batch_size=batch_size, epochs = epochs, validation_data = validation_data, callbacks=callbacks, initial_epoch=self.start_idx)\n        except:\n            if save:\n                df = pd.DataFrame.from_dict(history.history)\n                df.to_csv(hist, encoding='utf-8', index=False)\n            raise\n            sys.exit()\n        return self.history\n\n\n    def predict(self, x):\n        return self.model.predict(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/liverpool-ion-switching/train.csv')\ntest = pd.read_csv('/kaggle/input/liverpool-ion-switching/test.csv')['signal']\ny = train['open_channels']\ntrain.drop(['open_channels','time'],axis=1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rolling_window(a, window):\n    beginning_nans = np.zeros(shape=(int(window-1),))\n    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n    strides = a.strides + (a.strides[-1],)\n    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numpy_rolling_signal = rolling_window(train.values.ravel(),1600)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 4_999_901","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y= y[:numpy_rolling_signal.shape[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape,numpy_rolling_signal.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WNC = WaveNetClassifier(input_shape=(numpy_rolling_signal.shape[1],1), output_shape=(10,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WNC.fit(numpy_rolling_signal,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}